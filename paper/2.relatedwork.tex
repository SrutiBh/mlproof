\section{Related Work}

\paragraph{Automatic Segmentation}

Multi-terabyte EM brain volumes require automatic segmentation~\cite{jain2010,kaynig10,Liu2014,NunezIglesias2013Machine,GALA2014,amelio_segmentation}, but this data can be hard to classify in cases with ambiguous intercellular space. 

The 2013 IEEE ISBI neurites 3D segmentation challenge~\cite{isbi_challenge} showed that existing algorithms which learn from expert-segmented training data still exhibit high error rates. NeuroProof \cite{neuroproof2013} allows interactive learning of agglomeration of over-segmentations of images, based on a random forest classifier. Vazquez-Reina et al.~\cite{amelio_segmentation} propose automatic 3D segmentation by taking whole EM volumes into account rather than a per section approach, then solving a fusion problem with a global context. Kaynig et al.~\cite{kaynig10} propose a random forest classifier coupled with an anisotropic smoothing prior in a conditional random field framework with 3D segment fusion. 

It is also possible to learn segmentation classification features directly from images with CNNs. Ronneberger et al.~\cite{RonnebergerFB15} use a contracting/expanding CNN path architecture to enable precise boundary localization with small amounts of training data. Lee et al.~\cite{lee2015recursive} recursively train very deep networks with 2D and 3D filters to detect boundaries. 

While these approaches make good progress, in general proofreading is required to improve them through generating more ground-truth segmentations.

Arganda-Carreras et al.~\cite{10.3389/fnana.2015.00142} posed the ISBI 2D EM segmentation challenge in 2012, where a 30-image corpus of fly cell `in/out' labels was used to train boundary detection. However, mouse brain EM data is more difficult than the ISBI 2012 challenge, as it contains much intercellular space which is hard to classify. 

Bogovic et al.~\cite{BogovicHJ13} learn 3D features, and show even that unsupervised learning can produce better features than hand-designs. In this paper, we extend the features reported by Bogovic et al. but limit the classification to 2D images rather than 3D. In this case, reconstruction is unnecessary and, instead of waiting for the alignment of the 3D output, proofreading can start immediately to maximize throughput.

\paragraph{Collaborative Interactive Segmentation}

Recent works attack the problem of massive volume segmentation through crowd-sourcing\cite{saalfeld09,anderson2011}. EyeWire~\cite{eyewire2012} asks novice users to participate in a segmentation game for segmenting neuronal structures using a semi-automatic algorithm. D2P ~\cite{Giuly2013DP2} uses a micro-labor workforce approach where local boolean decisions are combined to produce a consensus segmentation. In general, our goal is to correct the output of a segmentation which is thought to be good; hence, our tool would be used after learning a segmentation model to direct user attention to correct likely erroneous areas.

\paragraph{Proofreading Tools}
The bottleneck of editing an existing and imperfect automatic segmentation was identified by Peng et al. \cite{proofreading_bottleneck}. The authors developed software which supports three-dimensional proofreading. Also for 3D, Sicat et al. proposed a graph abstraction method to guide users to problematic regions indicating the need for corrections \cite{markus_proofreading}. Janelia Farms then introduced Raveler \cite{raveler}, a software targeting expert users by offering many parameters for tweaking the proofreading process at the cost of a higher complexity. Raveler also includes a simple 3D renderer to validate corrections across slices.

In 2014, Haehn et al. developed two proofreading tools: Mojo and Dojo. Mojo is a stand-alone proofreading tool with a simple scribble interface for error correction. The need for distributed proofreading lead us to develop Dojo, a web-based proofreading framework with a minimalistic user interface. The authors defined requirements for proofreading tools in general and then evaluated the accuracy and speed of Raveler, Mojo and Dojo through a quantitative user study (Sec. 3 and 4) \cite{haehn_dojo_2014}. 
Al-Awami et al. then integrated Dojo into their proofreading management system Neuroblocks \cite{Neuroblocks}. The system includes a scalable visualization for tracking the proofreading process among multiple users.

In 2015, Karimov et al. proposed a guided volume editing approach using histogram dissimilarity \cite{karimov_guided_volume_editing}. Measuring differences in histogram distributions helps their system to find potential errors and to suggest possible corrections. Their method shows promising results on Computed-Tomography Angiography datasets but is targeted towards expert users.

Recently, Uzunbas et al. showed that potential labeling errors can be found by taking the merge tree of an automatic segmentation method into account \cite{uzunbas}. The authors keep track of uncertainties during the automatic labeling and then present them as regions for proofreading. This requires access to the merge tree of the segmentation stage which is not always available.


%\subsection{Contributions}

%Given this, we contribute to the literature:
%\begin{enumerate}
%\item One contribution
%\item Two contribution
%\item (Maybe) three contribution
%\end{enumerate}